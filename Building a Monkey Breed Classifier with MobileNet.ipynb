{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MobileNet model\n",
    "\n",
    "Here, we will be freezing all the layers of the model, except the top 4 layers which we are gonna train with the monkey breed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 96s 6us/step\n",
      "0 .  InputLayer\n",
      "1 .  ZeroPadding2D\n",
      "2 .  Conv2D\n",
      "3 .  BatchNormalization\n",
      "4 .  ReLU\n",
      "5 .  DepthwiseConv2D\n",
      "6 .  BatchNormalization\n",
      "7 .  ReLU\n",
      "8 .  Conv2D\n",
      "9 .  BatchNormalization\n",
      "10 .  ReLU\n",
      "11 .  ZeroPadding2D\n",
      "12 .  DepthwiseConv2D\n",
      "13 .  BatchNormalization\n",
      "14 .  ReLU\n",
      "15 .  Conv2D\n",
      "16 .  BatchNormalization\n",
      "17 .  ReLU\n",
      "18 .  DepthwiseConv2D\n",
      "19 .  BatchNormalization\n",
      "20 .  ReLU\n",
      "21 .  Conv2D\n",
      "22 .  BatchNormalization\n",
      "23 .  ReLU\n",
      "24 .  ZeroPadding2D\n",
      "25 .  DepthwiseConv2D\n",
      "26 .  BatchNormalization\n",
      "27 .  ReLU\n",
      "28 .  Conv2D\n",
      "29 .  BatchNormalization\n",
      "30 .  ReLU\n",
      "31 .  DepthwiseConv2D\n",
      "32 .  BatchNormalization\n",
      "33 .  ReLU\n",
      "34 .  Conv2D\n",
      "35 .  BatchNormalization\n",
      "36 .  ReLU\n",
      "37 .  ZeroPadding2D\n",
      "38 .  DepthwiseConv2D\n",
      "39 .  BatchNormalization\n",
      "40 .  ReLU\n",
      "41 .  Conv2D\n",
      "42 .  BatchNormalization\n",
      "43 .  ReLU\n",
      "44 .  DepthwiseConv2D\n",
      "45 .  BatchNormalization\n",
      "46 .  ReLU\n",
      "47 .  Conv2D\n",
      "48 .  BatchNormalization\n",
      "49 .  ReLU\n",
      "50 .  DepthwiseConv2D\n",
      "51 .  BatchNormalization\n",
      "52 .  ReLU\n",
      "53 .  Conv2D\n",
      "54 .  BatchNormalization\n",
      "55 .  ReLU\n",
      "56 .  DepthwiseConv2D\n",
      "57 .  BatchNormalization\n",
      "58 .  ReLU\n",
      "59 .  Conv2D\n",
      "60 .  BatchNormalization\n",
      "61 .  ReLU\n",
      "62 .  DepthwiseConv2D\n",
      "63 .  BatchNormalization\n",
      "64 .  ReLU\n",
      "65 .  Conv2D\n",
      "66 .  BatchNormalization\n",
      "67 .  ReLU\n",
      "68 .  DepthwiseConv2D\n",
      "69 .  BatchNormalization\n",
      "70 .  ReLU\n",
      "71 .  Conv2D\n",
      "72 .  BatchNormalization\n",
      "73 .  ReLU\n",
      "74 .  ZeroPadding2D\n",
      "75 .  DepthwiseConv2D\n",
      "76 .  BatchNormalization\n",
      "77 .  ReLU\n",
      "78 .  Conv2D\n",
      "79 .  BatchNormalization\n",
      "80 .  ReLU\n",
      "81 .  DepthwiseConv2D\n",
      "82 .  BatchNormalization\n",
      "83 .  ReLU\n",
      "84 .  Conv2D\n",
      "85 .  BatchNormalization\n",
      "86 .  ReLU\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet was designed to work with 224x224 pixel images\n",
    "rows, cols = 224, 224\n",
    "\n",
    "model = MobileNet(weights = 'imagenet', \n",
    "                  include_top = False, \n",
    "                  input_shape = (rows, cols, 3))\n",
    "\n",
    "# Now, we will freeze the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Let's take a look at the layers\n",
    "for (i, layer) in enumerate(model.layers):\n",
    "    print(str(i), \". \", layer.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 86 layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function returning our FC Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFCHead(rest_model, num_classes):\n",
    "    \"\"\"\n",
    "        Creates the FC Head layer for the model which can\n",
    "        be placed onto the bottom layers\n",
    "    \"\"\"\n",
    "    top_model = rest_model.output\n",
    "    top_model = (GlobalAveragePooling2D())(top_model)\n",
    "    top_model = (Dense(1024, activation = 'relu'))(top_model)\n",
    "    top_model = (Dense(256, activation = 'relu'))(top_model)\n",
    "    top_model = (Dense(64, activation = 'relu'))(top_model)\n",
    "    top_model = (Dense(num_classes, activation = 'sigmoid'))(top_model)\n",
    "    \n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add our FC layers on top of MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer global_average_pooling2d_1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b85f0b1e5fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mFC_Head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddFCHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFC_Head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8c2e019ca43a>\u001b[0m in \u001b[0;36maddFCHead\u001b[0;34m(rest_model, num_classes)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0m\u001b[1;32m    886\u001b[0m                                               self.name)\n\u001b[1;32m    887\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    177\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer global_average_pooling2d_1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 10]"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "FC_Head = addFCHead(model, num_classes)\n",
    "\n",
    "model = Model(inputs = model.input, outputs = FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
